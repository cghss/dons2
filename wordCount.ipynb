{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e66e048-44ba-45ad-9806-617042c765a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pypdfium2 as pdfium\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93c9262b-b0dd-4d9e-b14b-ccb8bf223293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_new_pdf(file_path):\n",
    "    try:\n",
    "        pdf = pdfium.PdfDocument(file_path)\n",
    "        all_text = \"\"\n",
    "        outbreak_text = \"\"  # Initialize outbreak_text outside the loop\n",
    "        \n",
    "        # Extract text from the entire PDF document\n",
    "        for page_num in range(len(pdf)):\n",
    "            page = pdf[page_num]\n",
    "            textpage = page.get_textpage()\n",
    "            text = textpage.get_text_range()\n",
    "            # Convert all_text to lowercase\n",
    "            text = text.lower()\n",
    "            all_text += text + \" \"\n",
    "            \n",
    "        # Find the index of \"Disease Outbreak News\"\n",
    "        outbreak_index = all_text.find(\"disease outbreak news\")\n",
    "        if outbreak_index != -1:\n",
    "            # Find the first occurrence of a date after \"Disease Outbreak News\"\n",
    "            date_match = re.search(r'\\n\\b\\d{1,2}\\s+(?:january|february|march|april|may|june|july|august|september|october|november|december)\\s+\\d{4}\\b', all_text[outbreak_index:])\n",
    "            if date_match:\n",
    "                # Extract everything from \"Disease Outbreak News\" until the date\n",
    "                outbreak_text = all_text[outbreak_index + len(\"disease outbreak news\"):outbreak_index + date_match.end()].strip()\n",
    "                outbreak_text = outbreak_text.replace(\"\\r\\n\", \" \")\n",
    "                extracted_date = date_match.group(0)\n",
    "                extracted_date = extracted_date.replace(\"\\n\", \"\")\n",
    "\n",
    "    \n",
    "        # Find \"Description of the Situation\" or \"Situation at a Glance\" header\n",
    "        header_index = all_text.find(\"description of the situation\")\n",
    "        if header_index == -1:\n",
    "            header_index = all_text.find(\"situation at a glance\")\n",
    "        \n",
    "        if header_index != -1:\n",
    "            all_text = all_text[header_index:]\n",
    "        \n",
    "            # Remove Figures and Tables\n",
    "            all_text = re.sub(r'(\\r\\n)?figure\\s+\\d+.*?\\n', '', all_text)\n",
    "            all_text = re.sub(r'(\\r\\n)?table\\s+\\d+.*?\\n', '', all_text)\n",
    "            all_text = re.sub(r'\\r\\nsource:.*?\\r\\n', ' ', all_text)\n",
    "        \n",
    "            # Remove \"See all DONs related to this event\"\n",
    "            all_text = all_text.replace(\"\\r\\nsee all dons related to this event\", \"\")\n",
    "        \n",
    "            # Replace newline characters with space\n",
    "            all_text = all_text.replace(\"\\r\\n\", \" \")\n",
    "            \n",
    "            total_words = len(all_text.split())\n",
    "        \n",
    "        else:\n",
    "            print(\"Header not found in the PDF: \" + {file_path})\n",
    "        \n",
    "        return total_words, all_text, outbreak_text, extracted_date\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "438b5859-d267-477a-9458-5079fdc51a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing all PDF documents\n",
    "pdf_directory = \"new-pdfs\"\n",
    "\n",
    "data = []\n",
    "\n",
    "# Iterate over all PDF files in the directory\n",
    "for filename in os.listdir(pdf_directory):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        file_path = os.path.join(pdf_directory, filename)\n",
    "        total_words, all_text, outbreak_text, extracted_date = process_new_pdf(file_path)\n",
    "        if total_words is not None and all_text is not None and outbreak_text is not None:\n",
    "            data.append({'ID':outbreak_text,'PDF Name': filename, 'Word Count': total_words, 'Text': all_text, 'Date': extracted_date})\n",
    "\n",
    "# Create a DataFrame\n",
    "new_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5621ec4b-d466-47b6-a080-46ad2f2806bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>PDF Name</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>Text</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dengue - global situation 21 december 2023</td>\n",
       "      <td>Dengue- Global situation.pdf</td>\n",
       "      <td>5317</td>\n",
       "      <td>description of the situation global overview c...</td>\n",
       "      <td>21 december 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>avian influenza a h5n1 - united kingdom of gre...</td>\n",
       "      <td>30maAvian Influenza A H5N1 - United Kingdom of...</td>\n",
       "      <td>1703</td>\n",
       "      <td>description of the situation in late april, th...</td>\n",
       "      <td>30 may 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>measles - occupied palestinian territory 10 ja...</td>\n",
       "      <td>Measles.pdf</td>\n",
       "      <td>922</td>\n",
       "      <td>description of the situation from 1 january th...</td>\n",
       "      <td>10 january 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ebola virus disease - african region (afro), d...</td>\n",
       "      <td>26juEbola virus disease – Democratic Republic ...</td>\n",
       "      <td>1874</td>\n",
       "      <td>description of the situation on 25 june 2020, ...</td>\n",
       "      <td>26 june 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>japanese encephalitis - australia 28 april 2022</td>\n",
       "      <td>Japanese Encephalitis - Australia.pdf</td>\n",
       "      <td>1720</td>\n",
       "      <td>description of the situation on 7 march 2022, ...</td>\n",
       "      <td>28 april 2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  ID  \\\n",
       "0         dengue - global situation 21 december 2023   \n",
       "1  avian influenza a h5n1 - united kingdom of gre...   \n",
       "2  measles - occupied palestinian territory 10 ja...   \n",
       "3  ebola virus disease - african region (afro), d...   \n",
       "4    japanese encephalitis - australia 28 april 2022   \n",
       "\n",
       "                                            PDF Name  Word Count  \\\n",
       "0                       Dengue- Global situation.pdf        5317   \n",
       "1  30maAvian Influenza A H5N1 - United Kingdom of...        1703   \n",
       "2                                        Measles.pdf         922   \n",
       "3  26juEbola virus disease – Democratic Republic ...        1874   \n",
       "4              Japanese Encephalitis - Australia.pdf        1720   \n",
       "\n",
       "                                                Text              Date  \n",
       "0  description of the situation global overview c...  21 december 2023  \n",
       "1  description of the situation in late april, th...       30 may 2023  \n",
       "2  description of the situation from 1 january th...   10 january 2020  \n",
       "3  description of the situation on 25 june 2020, ...      26 june 2020  \n",
       "4  description of the situation on 7 march 2022, ...     28 april 2022  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe32735c-3792-4267-8c87-97474c85072f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(\"new_dons_length.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae666f97-d359-44fb-8c8f-aa639f995132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_old_pdf(file_path):\n",
    "    try:\n",
    "        pdf = pdfium.PdfDocument(file_path)\n",
    "        all_text = \"\"\n",
    "        outbreak_text = \"\"\n",
    "        extracted_date = \"\"\n",
    "        \n",
    "        # Extract text from the entire PDF document\n",
    "        for page_num in range(len(pdf)):\n",
    "            page = pdf[page_num]\n",
    "            textpage = page.get_textpage()\n",
    "            text = textpage.get_text_range()\n",
    "            # Convert all_text to lowercase\n",
    "            text = text.lower()\n",
    "            all_text += text + \" \"\n",
    "        \n",
    "        # Define the patterns to search for\n",
    "        patterns = [\"disease outbreak news\", \"diseaseoutbreaknews\", \"disease outbreak news (dons)\"]\n",
    "        \n",
    "        # Initialize the index to store the result\n",
    "        outbreak_index = -1\n",
    "        \n",
    "        # Iterate over the patterns and search for each one\n",
    "        for pattern in patterns:\n",
    "            index = all_text.find(pattern, 0, 150)\n",
    "            if index != -1:\n",
    "                outbreak_index = index\n",
    "                break\n",
    "        \n",
    "        if outbreak_index != -1:\n",
    "            # Find the first occurrence of a date after \"Disease Outbreak News\"\n",
    "            date_match = re.search(r'(?:^|\\n)\\b\\d{1,2}\\s*(?:january|february|march|april|may|june|july|august|september|october|november|december)\\s*\\d{4}\\b', all_text[outbreak_index:])\n",
    "            if date_match:\n",
    "                # Extract everything from \"Disease Outbreak News\" until the date\n",
    "                outbreak_text = all_text[:outbreak_index].strip()\n",
    "                outbreak_text = outbreak_text.replace(\"\\r\\n\", \" \")\n",
    "                \n",
    "                extracted_date = date_match.group(0)\n",
    "                extracted_date = extracted_date.replace(\"\\n\", \"\")\n",
    "                \n",
    "                # Find the position of the matched date string in all_text\n",
    "                date_index = all_text.find(extracted_date)\n",
    "                if date_index != -1:\n",
    "                    # Cut out everything from all_text before and including the date\n",
    "                    all_text = all_text[date_index + len(extracted_date):]\n",
    "                    \n",
    "                    # Remove stuff\n",
    "                    all_text = re.sub(r'(\\r\\n)?figure\\s+\\d+.*?\\n', '', all_text)\n",
    "                    all_text = re.sub(r'(\\r\\n)?table\\s+\\d+.*?\\n', '', all_text)\n",
    "                    all_text = re.sub(r'\\r\\nsource:.*?\\r\\n', ' ', all_text)\n",
    "                \n",
    "                    all_text = all_text.replace(\"see all dons related to this event\", \"\")\n",
    "                    all_text = all_text.replace(\"\\r\\nhome\", \"\")\n",
    "                    all_text = all_text.replace(\"\\r\\nalert and response operations\", \"\")\n",
    "                    all_text = all_text.replace(\"diseases\\r\\nbiorisk reduction\\r\\ndisease outbreak news\", \"\")\n",
    "                    all_text = all_text.replace(\"\\r\\nemergencies preparedness, response\", \"\")\n",
    "                    all_text = all_text.replace(\"\\r\\nmenu\", \"\")\n",
    "                    all_text = all_text.replace(\"what we do regions about us\",\"\")\n",
    "                    all_text = all_text.replace(\"subscribe to our newsletters\",\"\")\n",
    "                    all_text = all_text.replace(\"privacy legal notice\",\"\")\n",
    "                    all_text = all_text.replace(\"© 2017 who\",\"\")\n",
    "                    all_text = all_text.replace(\"© 2018 who\",\"\")\n",
    "                    all_text = all_text.replace(\"© 2019 who\",\"\")\n",
    "                    all_text = all_text.replace(\"© 2020 who\",\"\")\n",
    "                    all_text = all_text.replace(\"© 2021 who\",\"\")\n",
    "        \n",
    "                    all_text = all_text.replace(\"\\r\\n\", \" \")\n",
    "        \n",
    "                    all_text = all_text.replace(\" - \", \" \")\n",
    "        \n",
    "                    total_words = len(all_text.split())\n",
    "        \n",
    "        else:\n",
    "                \n",
    "            # Find \"Description of the Situation\" or \"Situation at a Glance\" header\n",
    "            header_index = all_text.find(\"weekly update\\r\\n\",0,150)\n",
    "            # if header_index == -1:\n",
    "            #     header_index = all_text.find(\"situation at a glance\")\n",
    "            \n",
    "            if header_index != -1:\n",
    "                all_text = all_text[header_index:]\n",
    "                        \n",
    "                # Remove stuff\n",
    "                all_text = re.sub(r'(\\r\\n)?figure\\s+\\d+.*?\\n', '', all_text)\n",
    "                all_text = re.sub(r'(\\r\\n)?table\\s+\\d+.*?\\n', '', all_text)\n",
    "                all_text = re.sub(r'\\r\\nsource:.*?\\r\\n', ' ', all_text)\n",
    "            \n",
    "                all_text = all_text.replace(\"see all dons related to this event\", \"\")\n",
    "                all_text = all_text.replace(\"\\r\\nhome\", \"\")\n",
    "                all_text = all_text.replace(\"\\r\\nalert and response operations\", \"\")\n",
    "                all_text = all_text.replace(\"diseases\\r\\nbiorisk reduction\\r\\ndisease outbreak news\", \"\")\n",
    "                all_text = all_text.replace(\"\\r\\nemergencies preparedness, response\", \"\")\n",
    "                all_text = all_text.replace(\"\\r\\nmenu\", \"\")\n",
    "                all_text = all_text.replace(\"what we do regions about us\",\"\")\n",
    "                all_text = all_text.replace(\"subscribe to our newsletters\",\"\")\n",
    "                all_text = all_text.replace(\"privacy legal notice\",\"\")\n",
    "                all_text = all_text.replace(\"© 2017 who\",\"\")\n",
    "                all_text = all_text.replace(\"© 2018 who\",\"\")\n",
    "                all_text = all_text.replace(\"© 2019 who\",\"\")\n",
    "                all_text = all_text.replace(\"© 2020 who\",\"\")\n",
    "                all_text = all_text.replace(\"© 2021 who\",\"\")\n",
    "        \n",
    "                all_text = all_text.replace(\"\\r\\n\", \" \")\n",
    "        \n",
    "                all_text = all_text.replace(\" - \", \" \")\n",
    "        \n",
    "                total_words = len(all_text.split())\n",
    "                \n",
    "            else:\n",
    "                date_match = re.search(r'(?:^|\\n)\\b\\d{1,2}\\s*(?:january|february|march|april|may|june|july|august|september|october|november|december)\\s*\\d{4}\\b', all_text)\n",
    "                if date_match:\n",
    "                    # Extract the matched date\n",
    "                    extracted_date = date_match.group(0)\n",
    "                \n",
    "                    # Find the index of the extracted date in the text\n",
    "                    date_index = all_text.find(extracted_date)\n",
    "                \n",
    "                    if date_index != -1:\n",
    "                        # Find the index of the next newline character after the date\n",
    "                        next_newline_index = all_text.find('\\r\\n', date_index)\n",
    "                        \n",
    "                        if next_newline_index != -1:\n",
    "                            table_madness = all_text.find(\"following table and map.\\r\\n\")\n",
    "        \n",
    "                            \n",
    "                            if table_madness != -1:\n",
    "                                table_total = all_text.find('grand total', table_madness)\n",
    "                                table_end = all_text.find('\\r\\n', table_total)\n",
    "                                all_text = all_text[:table_madness + len(\"following table and map.\\r\\n\")] + all_text[table_end:]\n",
    "                                \n",
    "                            # Cut out everything before the date and the date itself until the next line\n",
    "                            all_text = all_text[next_newline_index+1:].strip()\n",
    "                            # Remove stuff\n",
    "                            all_text = re.sub(r'(\\r\\n)?figure\\s+\\d+.*?\\n', '', all_text)\n",
    "                            all_text = re.sub(r'(\\r\\n)?table\\s+\\d+.*?\\n', '', all_text)\n",
    "                            all_text = re.sub(r'\\r\\nsource:.*?\\r\\n', ' ', all_text)\n",
    "                        \n",
    "                            all_text = all_text.replace(\"see all dons related to this event\", \"\")\n",
    "                            all_text = all_text.replace(\"\\r\\nhome\", \"\")\n",
    "                            all_text = all_text.replace(\"\\r\\nalert and response operations\", \"\")\n",
    "                            all_text = all_text.replace(\"diseases\\r\\nbiorisk reduction\\r\\ndisease outbreak news\", \"\")\n",
    "                            all_text = all_text.replace(\"\\r\\nemergencies preparedness, response\", \"\")\n",
    "                            all_text = all_text.replace(\"\\r\\nmenu\", \"\")\n",
    "                            all_text = all_text.replace(\"what we do regions about us\",\"\")\n",
    "                            all_text = all_text.replace(\"subscribe to our newsletters\",\"\")\n",
    "                            all_text = all_text.replace(\"privacy legal notice\",\"\")\n",
    "                            all_text = all_text.replace(\"© 2017 who\",\"\")\n",
    "                            all_text = all_text.replace(\"© 2018 who\",\"\")\n",
    "                            all_text = all_text.replace(\"© 2019 who\",\"\")\n",
    "                            all_text = all_text.replace(\"© 2020 who\",\"\")\n",
    "                            all_text = all_text.replace(\"© 2021 who\",\"\")\n",
    "        \n",
    "                            all_text = all_text.replace(\"\\r\\n\", \" \")\n",
    "                            all_text = all_text.replace(\" - \", \" \")\n",
    "                    \n",
    "                            total_words = len(all_text.split())\n",
    "                            \n",
    "        return total_words, all_text, outbreak_text, extracted_date\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a30d221-91a4-412b-a66b-95ebb8914dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing old-pdfs/csr_don_2003_07_03_en_.pdf: cannot access local variable 'total_words' where it is not associated with a value\n",
      "Error processing old-pdfs/csr_don_2003_06_23_en_.pdf: cannot access local variable 'total_words' where it is not associated with a value\n",
      "Error processing old-pdfs/csr_don_2003_07_02_en_.pdf: cannot access local variable 'total_words' where it is not associated with a value\n",
      "Error processing old-pdfs/csr_don_2003_06_20_en_.pdf: cannot access local variable 'total_words' where it is not associated with a value\n",
      "Error processing old-pdfs/csr_don_2003_06_30_en_.pdf: cannot access local variable 'total_words' where it is not associated with a value\n",
      "Error processing old-pdfs/csr_don_2003_06_16_en_.pdf: cannot access local variable 'total_words' where it is not associated with a value\n",
      "Error processing old-pdfs/csr_don_2003_06_17_en_.pdf: cannot access local variable 'total_words' where it is not associated with a value\n",
      "Error processing old-pdfs/csr_don_2009_11_01_en_.pdf: cannot access local variable 'total_words' where it is not associated with a value\n",
      "Error processing old-pdfs/csr_don_2003_06_24_en_.pdf: cannot access local variable 'total_words' where it is not associated with a value\n",
      "Error processing old-pdfs/csr_don_2003_07_05_en_.pdf: cannot access local variable 'total_words' where it is not associated with a value\n",
      "Error processing old-pdfs/csr_don_2003_06_25_en_.pdf: cannot access local variable 'total_words' where it is not associated with a value\n",
      "Error processing old-pdfs/csr_don_2003_06_27_en_.pdf: cannot access local variable 'total_words' where it is not associated with a value\n",
      "Error processing old-pdfs/csr_don_2003_06_26_en_.pdf: cannot access local variable 'total_words' where it is not associated with a value\n",
      "Error processing old-pdfs/csr_don_2003_06_19_en_.pdf: cannot access local variable 'total_words' where it is not associated with a value\n",
      "Error processing old-pdfs/csr_don_2009_08_21_en_.pdf: cannot access local variable 'total_words' where it is not associated with a value\n"
     ]
    }
   ],
   "source": [
    "# Directory containing all PDF documents\n",
    "pdf_directory = \"old-pdfs\"\n",
    "\n",
    "data = []\n",
    "\n",
    "# Iterate over all PDF files in the directory\n",
    "for filename in os.listdir(pdf_directory):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        file_path = os.path.join(pdf_directory, filename)\n",
    "        total_words, all_text, outbreak_text, extracted_date = process_old_pdf(file_path)\n",
    "\n",
    "        # Regular expression pattern to extract date components from file path\n",
    "        file_path_pattern = r'csr_don_(\\d{4})_(\\d{2})_(\\d{2})_en_\\.pdf'\n",
    "        \n",
    "        # Search for the date components in the file path\n",
    "        file_path_match = re.search(file_path_pattern, file_path)\n",
    "        \n",
    "        # Extracted date from file path\n",
    "        if extracted_date == \"\" and file_path_match:\n",
    "            # Extract year, month, and day components\n",
    "            year, month, day = file_path_match.groups()\n",
    "            # Construct the date string in the desired format\n",
    "            extracted_date = datetime(int(year), int(month), int(day)).strftime(\"%d %B %Y\")        \n",
    "\n",
    "        if total_words is not None and all_text is not None and outbreak_text is not None:\n",
    "            data.append({'ID':outbreak_text,'PDF Name': filename, 'Word Count': total_words, 'Text': all_text, 'Date': extracted_date})\n",
    "\n",
    "# Create a DataFrame\n",
    "old_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d4eaf42-5d3d-482a-a40b-a0a511f9eb52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>PDF Name</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>Text</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>emergencies preparedness, response</td>\n",
       "      <td>csr_don_2003_01_21_en_.pdf</td>\n",
       "      <td>98</td>\n",
       "      <td>disease outbreak reported following the previ...</td>\n",
       "      <td>21 january 2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>emergencies preparedness, response</td>\n",
       "      <td>csr_don_2004_02_03_en_.pdf</td>\n",
       "      <td>147</td>\n",
       "      <td>the ministry of health in viet nam has today ...</td>\n",
       "      <td>3 february 2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>middle east respiratory syndrome coronavirus (...</td>\n",
       "      <td>csr_don_31-august-2018-mers-united-kingdom_en_...</td>\n",
       "      <td>1022</td>\n",
       "      <td>on 22 august 2018, the international health r...</td>\n",
       "      <td>31 august 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>emergencies preparedness, response</td>\n",
       "      <td>csr_don_2004_02_13_en_.pdf</td>\n",
       "      <td>97</td>\n",
       "      <td>situation (human) in thailand the ministry of...</td>\n",
       "      <td>13 february 2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>global alert and response (gar)</td>\n",
       "      <td>csr_don_2009_02_09_en_.pdf</td>\n",
       "      <td>112</td>\n",
       "      <td>the ministry of health and population of egyp...</td>\n",
       "      <td>9 february 2009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  ID  \\\n",
       "0                 emergencies preparedness, response   \n",
       "1                 emergencies preparedness, response   \n",
       "2  middle east respiratory syndrome coronavirus (...   \n",
       "3                 emergencies preparedness, response   \n",
       "4                    global alert and response (gar)   \n",
       "\n",
       "                                            PDF Name  Word Count  \\\n",
       "0                         csr_don_2003_01_21_en_.pdf          98   \n",
       "1                         csr_don_2004_02_03_en_.pdf         147   \n",
       "2  csr_don_31-august-2018-mers-united-kingdom_en_...        1022   \n",
       "3                         csr_don_2004_02_13_en_.pdf          97   \n",
       "4                         csr_don_2009_02_09_en_.pdf         112   \n",
       "\n",
       "                                                Text              Date  \n",
       "0   disease outbreak reported following the previ...   21 january 2003  \n",
       "1   the ministry of health in viet nam has today ...   3 february 2004  \n",
       "2   on 22 august 2018, the international health r...    31 august 2018  \n",
       "3   situation (human) in thailand the ministry of...  13 february 2004  \n",
       "4   the ministry of health and population of egyp...   9 february 2009  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "397dfab7-603b-4421-82a3-caed77f7aa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_df.to_csv(\"old_dons_length.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9fd00f1-1aa4-4774-bbf1-c82249c0b02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df = pd.concat([new_df, old_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07d1a7c5-24fe-427e-8bf1-0f40d3273dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df = concatenated_df.drop(columns={\"Text\",\"ID\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa75538a-17b9-4c27-bb9a-84eac97cdb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df.to_csv(\"dons_words.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e45017d-f4b6-4b8a-93bf-68aaafccfbea",
   "metadata": {},
   "source": [
    "## testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e9975859-8b8e-4532-b40a-5c59cd0fd775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf = pdfium.PdfDocument(\"old-pdfs/csr_don_2009_06_24_en_.pdf\")\n",
    "# all_text = \"\"\n",
    "# outbreak_text = \"\"\n",
    "# extracted_date = \"\"\n",
    "\n",
    "# # Extract text from the entire PDF document\n",
    "# for page_num in range(len(pdf)):\n",
    "#     page = pdf[page_num]\n",
    "#     textpage = page.get_textpage()\n",
    "#     text = textpage.get_text_range()\n",
    "#     # Convert all_text to lowercase\n",
    "#     text = text.lower()\n",
    "#     all_text += text + \" \"\n",
    "\n",
    "# # Define the patterns to search for\n",
    "# patterns = [\"disease outbreak news\", \"diseaseoutbreaknews\", \"disease outbreak news (dons)\"]\n",
    "\n",
    "# # Initialize the index to store the result\n",
    "# outbreak_index = -1\n",
    "\n",
    "# # Iterate over the patterns and search for each one\n",
    "# for pattern in patterns:\n",
    "#     index = all_text.find(pattern, 0, 150)\n",
    "#     if index != -1:\n",
    "#         outbreak_index = index\n",
    "#         break\n",
    "\n",
    "# if outbreak_index != -1:\n",
    "#     # Find the first occurrence of a date after \"Disease Outbreak News\"\n",
    "#     date_match = re.search(r'(?:^|\\n)\\b\\d{1,2}\\s*(?:january|february|march|april|may|june|july|august|september|october|november|december)\\s*\\d{4}\\b', all_text[outbreak_index:])\n",
    "#     if date_match:\n",
    "#         # Extract everything from \"Disease Outbreak News\" until the date\n",
    "#         outbreak_text = all_text[:outbreak_index].strip()\n",
    "#         outbreak_text = outbreak_text.replace(\"\\r\\n\", \" \")\n",
    "        \n",
    "#         extracted_date = date_match.group(0)\n",
    "#         extracted_date = extracted_date.replace(\"\\n\", \"\")\n",
    "        \n",
    "#         # Find the position of the matched date string in all_text\n",
    "#         date_index = all_text.find(extracted_date)\n",
    "#         if date_index != -1:\n",
    "#             # Cut out everything from all_text before and including the date\n",
    "#             all_text = all_text[date_index + len(extracted_date):]\n",
    "            \n",
    "#             # Remove stuff\n",
    "#             all_text = re.sub(r'(\\r\\n)?figure\\s+\\d+.*?\\n', '', all_text)\n",
    "#             all_text = re.sub(r'(\\r\\n)?table\\s+\\d+.*?\\n', '', all_text)\n",
    "#             all_text = re.sub(r'\\r\\nsource:.*?\\r\\n', ' ', all_text)\n",
    "        \n",
    "#             all_text = all_text.replace(\"see all dons related to this event\", \"\")\n",
    "#             all_text = all_text.replace(\"\\r\\nhome\", \"\")\n",
    "#             all_text = all_text.replace(\"\\r\\nalert and response operations\", \"\")\n",
    "#             all_text = all_text.replace(\"diseases\\r\\nbiorisk reduction\\r\\ndisease outbreak news\", \"\")\n",
    "#             all_text = all_text.replace(\"\\r\\nemergencies preparedness, response\", \"\")\n",
    "#             all_text = all_text.replace(\"\\r\\nmenu\", \"\")\n",
    "#             all_text = all_text.replace(\"what we do regions about us\",\"\")\n",
    "#             all_text = all_text.replace(\"subscribe to our newsletters\",\"\")\n",
    "#             all_text = all_text.replace(\"privacy legal notice\",\"\")\n",
    "#             all_text = all_text.replace(\"© 2020 who\",\"\")\n",
    "#             all_text = all_text.replace(\"© 2021 who\",\"\")\n",
    "\n",
    "#             all_text = all_text.replace(\"\\r\\n\", \" \")\n",
    "\n",
    "#             all_text = all_text.replace(\" - \", \" \")\n",
    "\n",
    "#             total_words = len(all_text.split())\n",
    "\n",
    "# else:\n",
    "        \n",
    "#     # Find \"Description of the Situation\" or \"Situation at a Glance\" header\n",
    "#     header_index = all_text.find(\"weekly update\\r\\n\",0,150)\n",
    "#     # if header_index == -1:\n",
    "#     #     header_index = all_text.find(\"situation at a glance\")\n",
    "    \n",
    "#     if header_index != -1:\n",
    "#         all_text = all_text[header_index:]\n",
    "                \n",
    "#         # Remove stuff\n",
    "#         all_text = re.sub(r'(\\r\\n)?figure\\s+\\d+.*?\\n', '', all_text)\n",
    "#         all_text = re.sub(r'(\\r\\n)?table\\s+\\d+.*?\\n', '', all_text)\n",
    "#         all_text = re.sub(r'\\r\\nsource:.*?\\r\\n', ' ', all_text)\n",
    "    \n",
    "#         all_text = all_text.replace(\"see all dons related to this event\", \"\")\n",
    "#         all_text = all_text.replace(\"\\r\\nhome\", \"\")\n",
    "#         all_text = all_text.replace(\"\\r\\nalert and response operations\", \"\")\n",
    "#         all_text = all_text.replace(\"diseases\\r\\nbiorisk reduction\\r\\ndisease outbreak news\", \"\")\n",
    "#         all_text = all_text.replace(\"\\r\\nemergencies preparedness, response\", \"\")\n",
    "#         all_text = all_text.replace(\"\\r\\nmenu\", \"\")\n",
    "#         all_text = all_text.replace(\"what we do regions about us\",\"\")\n",
    "#         all_text = all_text.replace(\"subscribe to our newsletters\",\"\")\n",
    "#         all_text = all_text.replace(\"privacy legal notice\",\"\")\n",
    "#         all_text = all_text.replace(\"© 2020 who\",\"\")\n",
    "#         all_text = all_text.replace(\"© 2021 who\",\"\")\n",
    "\n",
    "#         all_text = all_text.replace(\"\\r\\n\", \" \")\n",
    "\n",
    "#         all_text = all_text.replace(\" - \", \" \")\n",
    "\n",
    "#         total_words = len(all_text.split())\n",
    "        \n",
    "#     else:\n",
    "#         date_match = re.search(r'(?:^|\\n)\\b\\d{1,2}\\s*(?:january|february|march|april|may|june|july|august|september|october|november|december)\\s*\\d{4}\\b', all_text)\n",
    "#         if date_match:\n",
    "#             # Extract the matched date\n",
    "#             extracted_date = date_match.group(0)\n",
    "        \n",
    "#             # Find the index of the extracted date in the text\n",
    "#             date_index = all_text.find(extracted_date)\n",
    "        \n",
    "#             if date_index != -1:\n",
    "#                 # Find the index of the next newline character after the date\n",
    "#                 next_newline_index = all_text.find('\\r\\n', date_index)\n",
    "                \n",
    "#                 if next_newline_index != -1:\n",
    "#                     table_madness = all_text.find(\"following table and map.\\r\\n\")\n",
    "\n",
    "                    \n",
    "#                     if table_madness != -1:\n",
    "#                         table_total = all_text.find('grand total', table_madness)\n",
    "#                         table_end = all_text.find('\\r\\n', table_total)\n",
    "#                         all_text = all_text[:table_madness + len(\"following table and map.\\r\\n\")] + all_text[table_end:]\n",
    "                        \n",
    "#                     # Cut out everything before the date and the date itself until the next line\n",
    "#                     all_text = all_text[next_newline_index+1:].strip()\n",
    "#                     # Remove stuff\n",
    "#                     all_text = re.sub(r'(\\r\\n)?figure\\s+\\d+.*?\\n', '', all_text)\n",
    "#                     all_text = re.sub(r'(\\r\\n)?table\\s+\\d+.*?\\n', '', all_text)\n",
    "#                     all_text = re.sub(r'\\r\\nsource:.*?\\r\\n', ' ', all_text)\n",
    "                \n",
    "#                     all_text = all_text.replace(\"see all dons related to this event\", \"\")\n",
    "#                     all_text = all_text.replace(\"\\r\\nhome\", \"\")\n",
    "#                     all_text = all_text.replace(\"\\r\\nalert and response operations\", \"\")\n",
    "#                     all_text = all_text.replace(\"diseases\\r\\nbiorisk reduction\\r\\ndisease outbreak news\", \"\")\n",
    "#                     all_text = all_text.replace(\"\\r\\nemergencies preparedness, response\", \"\")\n",
    "#                     all_text = all_text.replace(\"\\r\\nmenu\", \"\")\n",
    "#                     all_text = all_text.replace(\"what we do regions about us\",\"\")\n",
    "#                     all_text = all_text.replace(\"subscribe to our newsletters\",\"\")\n",
    "#                     all_text = all_text.replace(\"privacy legal notice\",\"\")\n",
    "#                     all_text = all_text.replace(\"© 2020 who\",\"\")\n",
    "#                     all_text = all_text.replace(\"© 2021 who\",\"\")\n",
    "#                     all_text = all_text.replace(\"\\r\\n\", \" \")\n",
    "#                     all_text = all_text.replace(\" - \", \" \")\n",
    "            \n",
    "#                     total_words = len(all_text.split())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
